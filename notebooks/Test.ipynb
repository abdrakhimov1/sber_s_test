{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "class ModelInterface:\n",
    "\n",
    "    \"\"\"Interface for model construction\"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, data, metrics, n_neighbours, data_processor):\n",
    "        self.data = data\n",
    "        self.metrics = metrics\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.data_processor = data_processor\n",
    "        self.users_idx = []\n",
    "        self.model = NearestNeighbors(metric=self.metrics, algorithm='brute', n_neighbors=self.n_neighbours, n_jobs=-1)\n",
    "\n",
    "    def model_fitter(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Fitting NearestNeighbors model.\n",
    "        \"\"\"\n",
    "\n",
    "        prepare_data, users_idx = self.data_processor.process_data(data=self.data)\n",
    "        self.model.fit(prepare_data)\n",
    "        self.users_idx = users_idx\n",
    "        return prepare_data\n",
    "\n",
    "    def model_nearest_neighbours_getter(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Finds nearest neighbour for all items/users.\n",
    "        :return: nearest neighbours\n",
    "        \"\"\"\n",
    "        prepare_data = self.model_fitter()\n",
    "        return self.model.kneighbors(prepare_data, n_neighbors=self.n_neighbours)\n",
    "\n",
    "    @abstractmethod\n",
    "    def predictions_counter(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Making predictions. Should be overwritten for each approach.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ModelInterface import ModelInterface\n",
    "\n",
    "\n",
    "class UserToUserApproach(ModelInterface):\n",
    "\n",
    "    \"\"\"\n",
    "    Prediction model for User to User approach.\n",
    "    Checking distance between users with provided metric.\n",
    "    Making predictions for each user with predictions_counter function\n",
    "    \"\"\"\n",
    "\n",
    "    def predictions_counter(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Counting neighbours and distances for each user.\n",
    "        Adding neighbours products in recommendations.\n",
    "        \"\"\"\n",
    "        distances, neighbours = self.model_nearest_neighbours_getter()\n",
    "        prediction_dict = dict()\n",
    "        for idx, user in enumerate(self.users_idx):\n",
    "            predictions = []\n",
    "            for each in neighbours[idx][1::]:\n",
    "                predictions += list(self.data.loc[self.data['row'] == each]['col'].values)\n",
    "                if len(predictions) >= 10:\n",
    "                    break\n",
    "            prediction_dict[user] = predictions\n",
    "        return prediction_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_metrics as metrics\n",
    "\n",
    "\n",
    "class SolutionAnalysis:\n",
    "\n",
    "    \"\"\"Counts MAP@10 score for model predictions\"\"\"\n",
    "\n",
    "    def __init__(self, prediction, test_dataframe):\n",
    "        self.prediction = prediction\n",
    "        self.test = test_dataframe\n",
    "\n",
    "    def count_map_at_10(self):\n",
    "        \"\"\"Counts mapk10 from ml_metrics\"\"\"\n",
    "        self.test_reconfiguration()\n",
    "        return metrics.mapk(self.prediction, self.test, 10)\n",
    "\n",
    "    def test_reconfiguration(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Reconfigure self.test dataset intp valid form vor score counting.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        test_results = []\n",
    "        prediction_results = []\n",
    "        for each in self.test['row'].unique():\n",
    "            test_interactions = list(self.test.loc[self.test['row'] == each]['col'].values)\n",
    "            if len(test_interactions) > 0 and each in self.prediction.keys():\n",
    "                test_results.append(test_interactions)\n",
    "                prediction_results.append(self.prediction[each])\n",
    "        self.test = test_results\n",
    "        self.prediction = prediction_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from models.ModelInterface import ModelInterface\n",
    "\n",
    "\n",
    "class ItemToItemApproach(ModelInterface):\n",
    "\n",
    "    \"\"\"\n",
    "    Makes predictions with item to item approach.\n",
    "    Finds nearest items for each userItem.\n",
    "    Counts appearance of item for each users item recommendation with distance weight.\n",
    "    Recommends top10 items with most weights for user.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_prediction_for_user(self, prediction_dict):\n",
    "        users_list = self.data['row'].unique()\n",
    "        return_dict = dict()\n",
    "        for each_user in users_list:\n",
    "            counter = Counter()\n",
    "            for each_item in self.data.loc[self.data['row'] == each_user]['col'].values:\n",
    "                if each_item in prediction_dict.keys():\n",
    "                    for each_predicted_item, item_distance in zip(prediction_dict[each_item][0],\n",
    "                                                                  prediction_dict[each_item][1]):\n",
    "                        counter[each_predicted_item] += 1 * (1 - item_distance)\n",
    "            return_dict[each_user] = [x[0] for x in counter.most_common(10)]\n",
    "        return return_dict\n",
    "\n",
    "    def predictions_counter(self):\n",
    "        distances, neighbours = self.model_nearest_neighbours_getter()\n",
    "        prediction_dict = dict()\n",
    "        for idx, item in enumerate(self.users_idx):\n",
    "            prediction_dict[item] = (neighbours[idx], distances[idx])\n",
    "        return self.make_prediction_for_user(prediction_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DataProcessor import DataProcessor\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class DataProcessorForUser(DataProcessor):\n",
    "\n",
    "    def __init__(self, user_region_data, user_age_data):\n",
    "        self.user_region_data = user_region_data\n",
    "        self.user_age_data = user_age_data\n",
    "\n",
    "    @staticmethod\n",
    "    def data_preparation(user_region_data):\n",
    "\n",
    "        \"\"\"\n",
    "        Making user dictionary from user  region or age\n",
    "        :param user_region_data:\n",
    "        :return: dictionary with age or region information.\n",
    "        \"\"\"\n",
    "\n",
    "        df = user_region_data.drop_duplicates(subset='row', keep=\"last\")\n",
    "        user_region_dict = pd.Series(df.col.values, index=df.row).to_dict()\n",
    "        return user_region_dict\n",
    "\n",
    "    def user_information_combiner(self, train_pivot_table, user_region_data, user_age_data):\n",
    "\n",
    "        \"\"\"\n",
    "        Adding information about user region and age into users pivot table.\n",
    "        :param train_pivot_table: users pivot table\n",
    "        :param user_region_data: user region dataframe\n",
    "        :param user_age_data: user age dataframe\n",
    "        :return: numpy matrix\n",
    "        \"\"\"\n",
    "\n",
    "        data_size = len(train_pivot_table.index)\n",
    "\n",
    "        regions = np.zeros(data_size, dtype=np.uint8)\n",
    "        ages = np.zeros(data_size, dtype=np.uint8)\n",
    "\n",
    "        user_region_dict = self.data_preparation(user_region_data)\n",
    "        user_age_dict = self.data_preparation(user_age_data)\n",
    "\n",
    "        regions_list = user_region_data['col'].unique()\n",
    "        ages_list = user_age_data['col'].unique()\n",
    "\n",
    "        for idx, i in enumerate(train_pivot_table.index):\n",
    "\n",
    "            if i in user_region_dict.keys():\n",
    "                regions[idx] = user_region_dict[i] / 10\n",
    "            else:\n",
    "                regions[idx] = random.choice(regions_list)\n",
    "\n",
    "            if i in user_age_dict.keys():\n",
    "                ages[idx] = user_age_dict[i]\n",
    "            else:\n",
    "                ages[idx] = random.choice(ages_list)\n",
    "\n",
    "        numpy_pivot_table_in_unit8_format = train_pivot_table.values.astype(np.uint8)\n",
    "\n",
    "        for each in [regions, ages]:\n",
    "            numpy_pivot_table_in_unit8_format = np.hstack(\n",
    "                (numpy_pivot_table_in_unit8_format, each.reshape((data_size, 1))))\n",
    "\n",
    "        return numpy_pivot_table_in_unit8_format\n",
    "\n",
    "    def process_data(self, data):\n",
    "\n",
    "        \"\"\"Data converter from pandas dataframe to sparse matrix\"\"\"\n",
    "\n",
    "        train_pivot_table = data.pivot(\n",
    "            index='row',\n",
    "            columns='col',\n",
    "            values='data',\n",
    "        ).fillna(0)\n",
    "\n",
    "        numpy_pivot_table_in_unit8_format = self.user_information_combiner(train_pivot_table, self.user_region_data, self.user_age_data)\n",
    "        csr_matrix_for_users = csr_matrix(numpy_pivot_table_in_unit8_format)\n",
    "        return csr_matrix_for_users, train_pivot_table.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from models.DataProcessor import DataProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataProcessorForItemsWithoutUserInfo(DataProcessor):\n",
    "\n",
    "    \"\"\"\n",
    "    Data processor for item-item approach without Users vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, item_asset_data, item_price_data, item_subclass_data):\n",
    "        self.item_asset_data = item_asset_data\n",
    "        self.item_price_data = item_price_data\n",
    "        self.item_subclass_data = item_subclass_data\n",
    "\n",
    "    @staticmethod\n",
    "    def data_preparation(data):\n",
    "\n",
    "        \"\"\"\n",
    "        Converting information about item assets and prices into dictionary\n",
    "        :param data:\n",
    "        :return: dictionary of items\n",
    "        \"\"\"\n",
    "\n",
    "        df = data.drop_duplicates(subset='row', keep=\"last\")\n",
    "        item_asset_dict = pd.Series(df.data.values, index=df.row).to_dict()\n",
    "        return item_asset_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def data_preparation_for_subclasses(data):\n",
    "\n",
    "        \"\"\"\n",
    "        Converting information about item subclass into dictionary\n",
    "        :param data:\n",
    "        :return: dictionary of items\n",
    "        \"\"\"\n",
    "\n",
    "        df = data.drop_duplicates(subset='row', keep=\"last\")\n",
    "        item_asset_dict = pd.Series(df.col.values, index=df.row).to_dict()\n",
    "        return item_asset_dict\n",
    "\n",
    "    def process_data(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Data converter from pandas dataframe to sparse matrix\n",
    "        :param data:\n",
    "        :return: csr_matrix with items\n",
    "        \"\"\"\n",
    "\n",
    "        item_assets_dict = self.data_preparation(self.item_asset_data)\n",
    "        item_prices_dict = self.data_preparation(self.item_price_data)\n",
    "        item_subclasses_dict = self.data_preparation_for_subclasses(self.item_subclass_data)\n",
    "\n",
    "        prepared_data = []\n",
    "        items_idx = []\n",
    "        for each in item_assets_dict.keys():\n",
    "            if each in item_prices_dict.keys() and each in item_subclasses_dict.keys():\n",
    "                prepared_data.append([item_assets_dict[each] * 100, item_prices_dict[each] * 100, item_subclasses_dict[each] / 1000])\n",
    "                items_idx.append(each)\n",
    "\n",
    "        numpy_table = np.array(prepared_data, dtype=float)\n",
    "        csr_matrix_for_users = csr_matrix(numpy_table)\n",
    "        print(numpy_table)\n",
    "        return csr_matrix_for_users, items_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DataProcessor import DataProcessor\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataProcessorForItems(DataProcessor):\n",
    "\n",
    "    \"\"\"\n",
    "    Data processor for items.\n",
    "    Combines all information about items in csr_matrix\n",
    "    This version includes users vector(information about users, who interacted items)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, item_asset_data, item_price_data, item_subclass_data):\n",
    "        self.item_asset_data = item_asset_data\n",
    "        self.item_price_data = item_price_data\n",
    "        self.item_subclass_data = item_subclass_data\n",
    "\n",
    "    @staticmethod\n",
    "    def data_preparation(data):\n",
    "\n",
    "        \"\"\"\n",
    "        Collects all items in one dict\n",
    "        :param data:\n",
    "        :return: dictionary containing items\n",
    "        \"\"\"\n",
    "\n",
    "        df = data.drop_duplicates(subset='row', keep=\"last\")\n",
    "        item_asset_dict = pd.Series(df.data.values, index=df.row).to_dict()\n",
    "        return item_asset_dict\n",
    "\n",
    "    def items_information_combiner(self, train_pivot_table, item_asset_data, item_price_data, item_subclass_data):\n",
    "\n",
    "        \"\"\"\n",
    "        Adding asset, price and subclass information into item-users pivot table.\n",
    "        :param train_pivot_table: ready pivot table with users as columns, items as rows with values [0, 1]\n",
    "        :param item_asset_data: item_asset dataframe\n",
    "        :param item_price_data: item_price dataframe\n",
    "        :param item_subclass_data: item_subclass dataframe\n",
    "        :return: numpy matrix\n",
    "        \"\"\"\n",
    "\n",
    "        data_size = len(train_pivot_table.index)\n",
    "\n",
    "        assets = np.zeros(data_size, dtype=np.uint8)\n",
    "        prices = np.zeros(data_size, dtype=np.uint8)\n",
    "        subclasses = np.zeros(data_size, dtype=np.uint8)\n",
    "\n",
    "        item_assets_dict = self.data_preparation(item_asset_data)\n",
    "        item_prices_dict = self.data_preparation(item_price_data)\n",
    "        item_subclasses_dict = self.data_preparation(item_subclass_data)\n",
    "\n",
    "        assets_mean = item_asset_data['data'].mean()\n",
    "        prices_mean = item_price_data['data'].mean()\n",
    "        subclasses_mean = item_subclass_data['data'].mean()\n",
    "\n",
    "        for idx, i in enumerate(train_pivot_table.index):\n",
    "\n",
    "            try:\n",
    "                assets[idx] = item_assets_dict[i]\n",
    "            except IndexError:\n",
    "                assets[idx] = assets_mean\n",
    "\n",
    "            try:\n",
    "                prices[idx] = item_prices_dict[i]\n",
    "            except IndexError:\n",
    "                prices[idx] = prices_mean\n",
    "\n",
    "            try:\n",
    "                subclasses[idx] = item_subclasses_dict[i]\n",
    "            except IndexError:\n",
    "                subclasses[idx] = subclasses_mean\n",
    "\n",
    "        numpy_pivot_table_in_unit8_format = train_pivot_table.values\n",
    "\n",
    "        for each in [assets, prices, subclasses]:\n",
    "            numpy_pivot_table_in_unit8_format = np.hstack(\n",
    "                (numpy_pivot_table_in_unit8_format, each.reshape((data_size, 1))))\n",
    "\n",
    "        return numpy_pivot_table_in_unit8_format\n",
    "\n",
    "    def process_data(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Data converter from pandas dataframe to sparse matrix\n",
    "        \"\"\"\n",
    "\n",
    "        train_pivot_table = data.pivot(\n",
    "            index='col',\n",
    "            columns='row',\n",
    "            values='data'\n",
    "        ).fillna(0)\n",
    "        numpy_pivot_table_in_unit8_format = train_pivot_table.values.astype(np.uint8)\n",
    "        csr_matrix_for_users = csr_matrix(numpy_pivot_table_in_unit8_format)\n",
    "        return csr_matrix_for_users, train_pivot_table.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "\n",
    "    \"\"\"\n",
    "    Interface class for DataProcessors\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_data(self, data):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CombinedApproach import CombinedApproach\n",
    "from models.DataProcessorForItems import DataProcessorForItems\n",
    "from models.DataProcessorForUser import DataProcessorForUser\n",
    "from models.ItemToItemApproach import ItemToItemApproach\n",
    "from models.SolutionAnalysis import SolutionAnalysis\n",
    "from models.UserToUserApproach import UserToUserApproach\n",
    "\n",
    "\n",
    "class CustomGridSearch:\n",
    "\n",
    "    \"\"\"\n",
    "    Custom grid search. Counts scores for different parameters. Returns best params with highest score\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            metrics_list,\n",
    "            n_neighbours_list,\n",
    "            data,\n",
    "            test,\n",
    "            item_asset,\n",
    "            item_price,\n",
    "            item_subclass,\n",
    "            user_region,\n",
    "            user_age):\n",
    "\n",
    "        self.metrics_list = metrics_list\n",
    "        self.n_neighbours_list = n_neighbours_list\n",
    "        self.data = data\n",
    "        self.test = test\n",
    "        self.item_asset = item_asset\n",
    "        self.item_price = item_price\n",
    "        self.item_subclass = item_subclass\n",
    "        self.user_region = user_region\n",
    "        self.user_age = user_age\n",
    "        self.max_score = 0\n",
    "        self.grid_result = []\n",
    "\n",
    "    def grid_search(self):\n",
    "        print(\"Starting grid search\")\n",
    "        for metric in self.metrics_list:\n",
    "            for n_neighbours in self.n_neighbours_list:\n",
    "                print('Params: ' + metric + ' ' + str(n_neighbours))\n",
    "\n",
    "                user_to_user = UserToUserApproach(\n",
    "                    self.data,\n",
    "                    metric,\n",
    "                    n_neighbours,\n",
    "                    DataProcessorForUser(self.user_region, self.user_age))\n",
    "\n",
    "                item_to_item = ItemToItemApproach(\n",
    "                    self.data,\n",
    "                    metric,\n",
    "                    n_neighbours,\n",
    "                    DataProcessorForItems(self.item_asset, self.item_price, self.item_subclass))\n",
    "\n",
    "                # combined_method = CombinedApproach(\n",
    "                #     self.data,\n",
    "                #     metric,\n",
    "                #     n_neighbours,\n",
    "                #     self.item_asset,\n",
    "                #     self.item_price,\n",
    "                #     self.item_subclass,\n",
    "                #     self.user_region,\n",
    "                #     self.user_age)\n",
    "\n",
    "                user_analyzer = SolutionAnalysis(user_to_user.predictions_counter(), self.test)\n",
    "                user_score = user_analyzer.count_map_at_10()\n",
    "\n",
    "                item_analyzer = SolutionAnalysis(item_to_item.predictions_counter(), self.test)\n",
    "                item_score = item_analyzer.count_map_at_10()\n",
    "\n",
    "                # combined_analyzer = SolutionAnalysis(combined_method.predictions_counter(), self.test)\n",
    "                # combined_score = combined_analyzer.count_map_at_10()\n",
    "\n",
    "                print('user_score: ' + str(user_score))\n",
    "                print('item_score: ' + str(item_score))\n",
    "                # print('combined_score: ' + str(combined_score))\n",
    "\n",
    "                if user_score > self.max_score:\n",
    "                    self.grid_result = [metric, n_neighbours, 'user_to_user']\n",
    "                    self.max_score = user_score\n",
    "\n",
    "                if item_score > self.max_score:\n",
    "                    self.grid_result = [metric, n_neighbours, 'item_to_item']\n",
    "                    self.max_score = item_score\n",
    "\n",
    "                # if combined_score > self.max_score:\n",
    "                #     self.grid_result = [metric, n_neighbours, 'combined_model']\n",
    "                #     self.max_score = combined_score\n",
    "\n",
    "    def best(self):\n",
    "        return self.max_score, self.grid_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from models.DataProcessorForItems import DataProcessorForItems\n",
    "from models.DataProcessorForUser import DataProcessorForUser\n",
    "from models.ItemToItemApproach import ItemToItemApproach\n",
    "from models.UserToUserApproach import UserToUserApproach\n",
    "\n",
    "\n",
    "class CombinedApproach:\n",
    "\n",
    "    \"\"\"\n",
    "    Combines user_to_user approach with item_to_item approach.\n",
    "    Counts predictions for user_to_user approach\n",
    "    Counts predictions for item_to_item approach\n",
    "    Finding intersections between predictions for each user\n",
    "    If intersection is less than 10, randomly adding items from predictions union.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, metrics, n_neighbours, item_asset, item_price, item_subclass, user_region, user_age):\n",
    "        self.item_to_item = ItemToItemApproach(\n",
    "            data,\n",
    "            metrics,\n",
    "            n_neighbours,\n",
    "            DataProcessorForItems(item_asset, item_price, item_subclass))\n",
    "        self.user_to_user = UserToUserApproach(\n",
    "            data,\n",
    "            metrics,\n",
    "            n_neighbours,\n",
    "            DataProcessorForUser(user_region, user_age))\n",
    "\n",
    "    def get_multiple_prediction(self):\n",
    "\n",
    "        items_answer = self.item_to_item.predictions_counter()\n",
    "        users_answer = self.user_to_user.predictions_counter()\n",
    "        combined_answer = dict()\n",
    "\n",
    "        for k, v in items_answer.items():\n",
    "            updated_set = set.intersection(set(v), set(users_answer[k]))\n",
    "            if len(updated_set) < 10:\n",
    "                while not len(updated_set) == 10:\n",
    "                    updated_set.add(random.choice(v + users_answer[k]))\n",
    "            combined_answer[k] = list(updated_set)\n",
    "        return combined_answer\n",
    "\n",
    "    def predictions_counter(self):\n",
    "        return self.get_multiple_prediction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.CustomGridSearch import CustomGridSearch\n",
    "\n",
    "\"\"\"\n",
    "Reading data\n",
    "\"\"\"\n",
    "interactions = pd.read_csv('data/interactions.csv')\n",
    "item_subclass = pd.read_csv('data/item_subclass.csv')\n",
    "item_price = pd.read_csv('data/item_price.csv')\n",
    "item_asset = pd.read_csv('data/item_asset.csv')\n",
    "user_region = pd.read_csv('data/user_region.csv')\n",
    "user_age = pd.read_csv('data/user_age.csv')\n",
    "\n",
    "\"\"\"\n",
    "Splitting data to train and test. Adding users, who wasn't included in train or test with zero vectors\n",
    "\"\"\"\n",
    "\n",
    "train, test = train_test_split(interactions, test_size=0.2, random_state=42, shuffle=True)\n",
    "mismatch_set = set(item_subclass['row']).difference(set(train['col'].values))\n",
    "new_dataframe = pd.DataFrame(data={\n",
    "    'row': [0 for _ in mismatch_set],\n",
    "    'col': list(mismatch_set),\n",
    "    'data': [0 for _ in mismatch_set]})\n",
    "mismatch_set_test = set(item_subclass['row']).difference(set(test['col'].values))\n",
    "new_dataframe_test = pd.DataFrame(data={\n",
    "    'row': [0 for _ in mismatch_set_test],\n",
    "    'col': list(mismatch_set_test),\n",
    "    'data': [0 for _ in mismatch_set_test]})\n",
    "train = pd.concat([train, new_dataframe])\n",
    "test = pd.concat([test, new_dataframe_test])\n",
    "\n",
    "\"\"\"\n",
    "Params for grid search\n",
    "\"\"\"\n",
    "metrics = ['cityblock', 'cosine', 'euclidean']\n",
    "n_neighbours_list = [3]\n",
    "\n",
    "\n",
    "\"\"\"Grid search \"\"\"\n",
    "grid = CustomGridSearch(metrics,\n",
    "                        n_neighbours_list,\n",
    "                        train,\n",
    "                        test,\n",
    "                        item_asset,\n",
    "                        item_price,\n",
    "                        item_subclass,\n",
    "                        user_region,\n",
    "                        user_age)\n",
    "\n",
    "grid.grid_search()\n",
    "print(grid.best())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
